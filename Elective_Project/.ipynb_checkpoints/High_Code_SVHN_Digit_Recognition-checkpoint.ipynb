{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q91KqmCRu64D"
   },
   "source": [
    "# **Deep Learning Project: Street View Housing Number Digit Recognition**\n",
    "\n",
    "# **Marks: 60**\n",
    "\n",
    "--------------\n",
    "## **Context** \n",
    "--------------\n",
    "\n",
    "One of the most interesting tasks in deep learning is to recognize objects in natural scenes. The ability to process visual information using machine learning algorithms can be very useful as demonstrated in various applications.\n",
    "\n",
    "The SVHN dataset contains over 600,000 labeled digits cropped from street-level photos. It is one of the most popular image recognition datasets. It has been used in neural networks created by Google to improve the map quality by automatically transcribing the address numbers from a patch of pixels. The transcribed number with a known street address helps pinpoint the location of the building it represents. \n",
    "\n",
    "----------------\n",
    "## **Objective**\n",
    "----------------\n",
    "\n",
    "Our objective is to predict the number depicted inside the image by using Artificial or Fully Connected Feed Forward Neural Networks and Convolutional Neural Networks. We will go through various models of each and finally select the one that is giving us the best performance. \n",
    "\n",
    "-------------\n",
    "## **Dataset**\n",
    "-------------\n",
    "Here, we will use a subset of the original data to save some computation time. The dataset is provided as a .h5 file. The basic preprocessing steps have been applied on the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8z2Z7-OAs8QG"
   },
   "source": [
    "## **Mount the drive**\n",
    "\n",
    "Let us start by mounting the Google drive. You can run the below cell to mount the Google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "03lDyQUuef7z"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8U3DUa3eNsT"
   },
   "source": [
    "## **Importing the necessary libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-dVzeuF3eQx1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ucnevGLoyKf_"
   },
   "source": [
    "**Let us check the version of tensorflow.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W5as47YxyJVk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8lsux2ZwyTTR"
   },
   "source": [
    "## **Load the dataset**\n",
    "\n",
    "- Let us now load the dataset that is available as a .h5 file.\n",
    "- Split the data into the train and the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BApX9qgNsqV0",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVe0CYpUgj7w"
   },
   "source": [
    "Check the number of images in the training and the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y3lwKpOefkpA"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "akTUOfLlgwoM"
   },
   "source": [
    "**Observation:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kxODV6HKykuc"
   },
   "source": [
    "## **Visualizing images**\n",
    "\n",
    "- Use X_train to visualize the first 10 images.\n",
    "- Use Y_train to print the first 10 labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bvsc8ytHsqWD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kzoyeXHOy80N"
   },
   "source": [
    "## **Data preparation**\n",
    "\n",
    "- Print the shape and the array of pixels for the first image in the training dataset.\n",
    "- Normalize the train and the test dataset by dividing by 255.\n",
    "- Print the new shapes of the train and the test dataset.\n",
    "- One-hot encode the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NqndzQXng9rL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4CQkKtQ0XII"
   },
   "source": [
    "### **Normalize the train and the test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q_yUUTp_mUzB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YSlYN6pb8kMY"
   },
   "source": [
    "Print the shapes of Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t7FSqOpamWkH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0uLxXBpz81vk"
   },
   "source": [
    "### **One-hot encode output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zL0lYER4sqWw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViqPOTquCF76"
   },
   "source": [
    "**Observation:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yH-gVrzuByNA"
   },
   "source": [
    "## **Model Building**\n",
    "\n",
    "Now that we have done the data preprocessing, let's build an ANN model.\n",
    "\n",
    "### Fix the seed for random number generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BcKRwrGn0XIL"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJDUoaEj1d6e"
   },
   "source": [
    "### **Model Architecture**\n",
    "- Write a function that returns a sequential model with the following architecture:\n",
    " - First hidden layer with **64 nodes and the relu activation** and the **input shape = (1024, )**\n",
    " - Second hidden layer with **32 nodes and the relu activation**\n",
    " - Output layer with **activation as 'softmax' and number of nodes equal to the number of classes, i.e., 10**\n",
    " - Compile the model with the **loss equal to categorical_crossentropy, optimizer equal to Adam(learning_rate = 0.001), and metric equal to 'accuracy'**. Do not fit the model here, just return the compiled model.\n",
    "- Call the nn_model_1 function and store the model in a new variable. \n",
    "- Print the summary of the model.\n",
    "- Fit on the train data with a **validation split of 0.2, batch size = 128, verbose = 1, and epochs = 20**. Store the model building history to use later for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A48z6ucF0XIP"
   },
   "source": [
    "### **Build and train an ANN model as per the above mentioned architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cmi81Gr5sqW-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MeF8XSWz0XIU"
   },
   "source": [
    "### **Plot the Training and Validation Accuracies and write down your Observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lt77zgGMP4yw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGBbQpLONX7k"
   },
   "source": [
    "**Observations:_______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0qgLMBZm5-K"
   },
   "source": [
    "Let's build one more model with higher complexity and see if we can improve the performance of the model. \n",
    "\n",
    "First, we need to clear the previous model's history from the Keras backend. Also, let's fix the seed again after clearing the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I_ih3wEU9wIk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT6o3TIKuCtk"
   },
   "source": [
    "### **Second Model Architecture**\n",
    "- Write a function that returns a sequential model with the following architecture:\n",
    " - First hidden layer with **256 nodes and the relu activation** and the **input shape = (1024, )**\n",
    " - Second hidden layer with **128 nodes and the relu activation**\n",
    " - Add the **Dropout layer with the rate equal to 0.2**\n",
    " - Third hidden layer with **64 nodes and the relu activation**\n",
    " - Fourth hidden layer with **64 nodes and the relu activation**\n",
    " - Fifth hidden layer with **32 nodes and the relu activation**\n",
    " - Add the **BatchNormalization layer**\n",
    " - Output layer with **activation as 'softmax' and number of nodes equal to the number of classes, i.e., 10**\n",
    " -Compile the model with the **loss equal to categorical_crossentropy, optimizer equal to Adam(learning_rate = 0.0005), and metric equal to 'accuracy'**. Do not fit the model here, just return the compiled model.\n",
    "- Call the nn_model_2 function and store the model in a new variable.\n",
    "- Print the summary of the model.\n",
    "- Fit on the train data with a **validation split of 0.2, batch size = 128, verbose = 1, and epochs = 30**. Store the model building history to use later for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f-ZjNBmH0XIV"
   },
   "source": [
    "### **Build and train the new ANN model as per the above mentioned architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEPYLFIPnSDP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJYsvjmw0XIX"
   },
   "source": [
    "### **Plot the Training and Validation Accuracies and write down your Observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01ig6BrF1KVy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPW1LlD61RDn"
   },
   "source": [
    "**Observations:_______**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8kuXx9Bvu00f"
   },
   "source": [
    "## **Predictions on the test data**\n",
    "\n",
    "- Make predictions on the test set using the second model.\n",
    "- Print the obtained results using the classification report and the confusion matrix.\n",
    "- Final observations on the obtained results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xbWMEtTj5Ad0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3li8Ib08yts"
   },
   "source": [
    "**Note:** Earlier, we noticed that each entry of the target variable is a one-hot encoded vector but to print the classification report and confusion matrix, we must convert each entry of y_test to a single label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NByu7uAQ8x9P"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_SIoopr0XIg"
   },
   "source": [
    "### **Print the classification report and the confusion matrix for the test predictions. Write your observations on the final results.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xRddeJ-3EHT1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DjErl4GA2u9s"
   },
   "source": [
    "**Final Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkR4JioMsuIV"
   },
   "source": [
    "## **Using Convolutional Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YN2YgkGL_6xQ"
   },
   "source": [
    "### **Load the dataset again and split the data into the train and the test dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mqM204HbAjP2",
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fPqF_xGAjQB"
   },
   "source": [
    "Check the number of images in the training and the testing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gTLJZWjPAjQB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qyMiP_rAjQB"
   },
   "source": [
    "**Observation:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OJndFfEVAjQG"
   },
   "source": [
    "## **Data preparation**\n",
    "\n",
    "- Print the shape and the array of pixels for the first image in the training dataset.\n",
    "- Reshape the train and the test dataset because we always have to give a 4D array as input to CNNs.\n",
    "- Normalize the train and the test dataset by dividing by 255.\n",
    "- Print the new shapes of the train and the test dataset.\n",
    "- One-hot encode the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W4uXqKz1AjQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "at30iiX1__7F"
   },
   "source": [
    "Reshape the dataset to be able to pass them to CNNs. Remember that we always have to give a 4D array as input to CNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9YPwf9ysqWU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ODYnoLfaAEGx"
   },
   "source": [
    "Normalize inputs from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eOGLAn40AjQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cS9T4HqjAoyM"
   },
   "source": [
    "Print New shape of Training and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5qf8S5NQAjQG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "10QaOV-xR7Jn"
   },
   "source": [
    "### **One-hot encode the labels in the target variable y_train and y_test.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3KHWFWKMAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H-8jYVQTAjQH"
   },
   "source": [
    "**Observation:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjx_LI4_AjQH"
   },
   "source": [
    "## **Model Building**\n",
    "\n",
    "Now that we have done data preprocessing, let's build a CNN model.\n",
    "Fix the seed for random number generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZY5pyF4-KDNt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JUAczhzAjQH"
   },
   "source": [
    "### **Model Architecture**\n",
    "- **Write a function** that returns a sequential model with the following architecture:\n",
    " - First Convolutional layer with **16 filters and the kernel size of 3x3**. Use the **'same' padding** and provide the **input shape = (32, 32, 1)**\n",
    " - Add a **LeakyRelu layer** with the **slope equal to 0.1**\n",
    " - Second Convolutional layer with **32 filters and the kernel size of 3x3 with 'same' padding**\n",
    " - Another **LeakyRelu** with the **slope equal to 0.1**\n",
    " - A **max-pooling layer** with a **pool size of 2x2**\n",
    " - **Flatten** the output from the previous layer\n",
    " - Add a **dense layer with 32 nodes**\n",
    " - Add a **LeakyRelu layer with the slope equal to 0.1**\n",
    " - Add the final **output layer with nodes equal to the number of classes, i.e., 10** and **'softmax' as the activation function**\n",
    " - Compile the model with the **loss equal to categorical_crossentropy, optimizer equal to Adam(learning_rate = 0.001), and metric equal to 'accuracy'**. Do not fit the model here, just return the compiled model.\n",
    "- Call the function cnn_model_1 and store the output in a new variable.\n",
    "- Print the summary of the model.\n",
    "- Fit the model on the training data with a **validation split of 0.2, batch size = 32, verbose = 1, and epochs = 20**. Store the model building history to use later for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JWsAd45JKDNu"
   },
   "source": [
    "### **Build and train a CNN model as per the above mentioned architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1jOYANWAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPzfIf9kKDNw"
   },
   "source": [
    "### **Plot the Training and Validation Accuracies and Write your observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07oUCr1kAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6zTLyp9AjQH"
   },
   "source": [
    "**Observations:__________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ukvtg2eMAjQH"
   },
   "source": [
    "Let's build another model and see if we can get a better model with generalized performance.\n",
    "\n",
    "First, we need to clear the previous model's history from the Keras backend. Also, let's fix the seed again after clearing the backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HbKi93HTolGW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ep19Jd8HAjQH"
   },
   "source": [
    "### **Second Model Architecture**\n",
    "\n",
    "- Write a function that returns a sequential model with the following architecture:\n",
    " - First Convolutional layer with **16 filters and the kernel size of 3x3**. Use the **'same' padding** and provide the **input shape = (32, 32, 1)**\n",
    " - Add a **LeakyRelu layer** with the **slope equal to 0.1**\n",
    " - Second Convolutional layer with **32 filters and the kernel size of 3x3 with 'same' padding**\n",
    " - Add **LeakyRelu** with the **slope equal to 0.1**\n",
    " - Add a **max-pooling layer** with a **pool size of 2x2**\n",
    " - Add a **BatchNormalization layer**\n",
    " - Third Convolutional layer with **32 filters and the kernel size of 3x3 with 'same' padding**\n",
    " - Add a **LeakyRelu layer with the slope equal to 0.1**\n",
    " - Fourth Convolutional layer **64 filters and the kernel size of 3x3 with 'same' padding** \n",
    " - Add a **LeakyRelu layer with the slope equal to 0.1**\n",
    " - Add a **max-pooling layer** with a **pool size of 2x2**\n",
    " - Add a **BatchNormalization layer**\n",
    " - **Flatten** the output from the previous layer\n",
    " - Add a **dense layer with 32 nodes**\n",
    " - Add a **LeakyRelu layer with the slope equal to 0.1**\n",
    " - Add a **dropout layer with the rate equal to 0.5**\n",
    " - Add the final **output layer with nodes equal to the number of classes, i.e., 10** and **'softmax' as the activation function**\n",
    " - Compile the model with the **categorical_crossentropy loss, adam optimizers (learning_rate = 0.001), and metric equal to 'accuracy'**. Do not fit the model here, just return the compiled model.\n",
    "- Call the function cnn_model_2 and store the model in a new variable.\n",
    "- Print the summary of the model.\n",
    "- Fit the model on the train data with a **validation split of 0.2, batch size = 128, verbose = 1, and epochs = 30**. Store the model building history to use later for visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y5IBLS1eKDNy"
   },
   "source": [
    "### **Build and train the second CNN model as per the above mentioned architecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wk9sl2UEAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PyhUtMy3KDN1"
   },
   "source": [
    "### **Plot the Training and Validation accuracies and write your observations.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YVQu7uWiAjQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qrrt0Ac3AjQH"
   },
   "source": [
    "**Observations:________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kja4SnOdAjQI"
   },
   "source": [
    "## **Predictions on the test data**\n",
    "\n",
    "- Make predictions on the test set using the second model.\n",
    "- Print the obtained results using the classification report and the confusion matrix.\n",
    "- Final observations on the obtained results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHCRwRbgKDN2"
   },
   "source": [
    "### **Make predictions on the test data using the second model.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f1d-VvaLAjQI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DrV1tOG0AjQI"
   },
   "source": [
    "**Note:** Earlier, we noticed that each entry of the target variable is a one-hot encoded vector, but to print the classification report and confusion matrix, we must convert each entry of y_test to a single label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUSHU9W0AjQI"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVCa-ysWKDN3"
   },
   "source": [
    "### **Write your final observations on the performance of the model on the test data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOMq2rCJAjQJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TNN9v713AjQJ"
   },
   "source": [
    "**Final Observations:_________**"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
